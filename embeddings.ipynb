{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"protein1\", \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"),\n",
    "    (\"protein2\", \"KALTARQQEVFDLIRDHISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "    (\"protein2 with mask\",\"KALTARQQEVFDLIRD<mask>ISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "    (\"protein3\",  \"K A <mask> I S Q\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([67, 73, 73,  8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 73, 1280])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 because the model has 33 layers. \n",
    "# This is kind of dumb, we should have a way of finding out the total number of layers\n",
    "# for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "padding_mask = batch_tokens.eq(model.padding_idx)\n",
    "for layer_idx, layer in enumerate(model.layers):\n",
    "    print(layer_idx)\n",
    "    # print(layer_idx)\n",
    "    # print(layer)\n",
    "    # x, attn = layer(\n",
    "    #     x,\n",
    "    #     self_attn_padding_mask=padding_mask,\n",
    "    #     need_head_weights=False,\n",
    "    # )\n",
    "    # print(x)\n",
    "    # print(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "for key, value in results[\"representations\"].items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits\n",
      "representations\n",
      "attentions\n",
      "contacts\n"
     ]
    }
   ],
   "source": [
    "for key, value in results.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0744, -0.0747,  0.0824,  ..., -0.2394,  0.1661, -0.0306],\n",
       "         [ 0.0826, -0.2050, -0.0171,  ...,  0.1044,  0.1343, -0.0945],\n",
       "         [-0.0528, -0.0635, -0.2515,  ..., -0.0461,  0.2368, -0.1214],\n",
       "         ...,\n",
       "         [ 0.0904, -0.0895,  0.0698,  ..., -0.2790,  0.1822, -0.0566],\n",
       "         [ 0.0960, -0.0847,  0.0674,  ..., -0.2860,  0.1888, -0.0324],\n",
       "         [ 0.0830, -0.0842,  0.0592,  ..., -0.2927,  0.1853, -0.0333]],\n",
       "\n",
       "        [[ 0.0819, -0.0513,  0.0804,  ..., -0.3185,  0.1573,  0.0690],\n",
       "         [-0.0232,  0.0039, -0.2268,  ...,  0.0346,  0.0886,  0.3810],\n",
       "         [ 0.0146, -0.0700, -0.1314,  ..., -0.0757,  0.3837,  0.0932],\n",
       "         ...,\n",
       "         [ 0.0198, -0.1917,  0.1589,  ..., -0.2205, -0.0567,  0.3618],\n",
       "         [-0.0704, -0.2010,  0.0613,  ..., -0.1972,  0.0557,  0.2920],\n",
       "         [ 0.1067, -0.0337,  0.0860,  ..., -0.4020,  0.1861,  0.0410]],\n",
       "\n",
       "        [[ 0.0822, -0.0485,  0.0707,  ..., -0.3180,  0.1576,  0.0736],\n",
       "         [-0.0306,  0.0159, -0.2224,  ...,  0.0337,  0.0905,  0.3866],\n",
       "         [ 0.0027, -0.0880, -0.1263,  ..., -0.0645,  0.3729,  0.1119],\n",
       "         ...,\n",
       "         [ 0.0223, -0.1949,  0.1578,  ..., -0.2128, -0.0532,  0.3670],\n",
       "         [-0.0614, -0.2066,  0.0610,  ..., -0.1855,  0.0545,  0.2896],\n",
       "         [ 0.1128, -0.0391,  0.0822,  ..., -0.3958,  0.1830,  0.0444]],\n",
       "\n",
       "        [[ 0.0258,  0.0027, -0.0926,  ..., -0.3163,  0.2515, -0.0867],\n",
       "         [-0.1017,  0.1130, -0.1198,  ...,  0.0412, -0.0769, -0.0411],\n",
       "         [-0.0122,  0.1260, -0.0289,  ...,  0.1321, -0.0693,  0.1053],\n",
       "         ...,\n",
       "         [-0.0491, -0.1060,  0.0958,  ..., -0.2429,  0.2183, -0.1301],\n",
       "         [-0.0297, -0.1069,  0.1000,  ..., -0.2500,  0.1972, -0.1327],\n",
       "         [-0.0170, -0.0898,  0.0907,  ..., -0.2487,  0.1829, -0.1536]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 73, 1280])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.0614, -0.0687,  0.0430,  ..., -0.1642, -0.0678,  0.0446]),\n",
       " tensor([ 0.0553, -0.0757,  0.0414,  ..., -0.3117, -0.0026,  0.1683]),\n",
       " tensor([ 0.0618, -0.0769,  0.0405,  ..., -0.3037, -0.0013,  0.1741]),\n",
       " tensor([ 0.0084,  0.1425,  0.0506,  ...,  0.0403, -0.1063,  0.0079])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_representations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67)\n",
      "tensor(73)\n",
      "tensor(73)\n",
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    print(tokens_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS330_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
